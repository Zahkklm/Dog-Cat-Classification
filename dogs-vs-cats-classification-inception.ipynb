{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"fe76d1d1ded592430e7548feacfa38dc42f085d9"},"source":["# Kütüphaneleri import ediyoruz"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd # CSV dosyası okuma\n","\n","from keras.preprocessing.image import ImageDataGenerator, load_img\n","from keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import random\n","\n","import os"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"7335a579cc0268fba5d34d6f7558f33c187eedb3"},"source":["# Train Verisini Oluşturma"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["filenames = os.listdir(\"../input/train/train\")\n","categories = []\n","for filename in filenames:\n","    category = filename.split('.')[0]\n","    if category == 'dog':\n","        categories.append(1)\n","    else:\n","        categories.append(0)\n","\n","df = pd.DataFrame({\n","    'filename': filenames,\n","    'category': categories\n","})\n","df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"a999484fc35b73373fafe2253ae9db7ff46fdb90"},"source":["### Kategori Toplamını Görüntüleme"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"fa26f0bc7a6d835a24989790b20f3c6f32946f45","trusted":true},"outputs":[],"source":["df['category'].value_counts().plot.bar()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"400a293df3c8499059d9175f3915187074efd971"},"source":["# Örnek Bir Resim Görüntüleme"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"602b40f7353871cb161c60b5237f0da0096b2f47","trusted":true},"outputs":[],"source":["sample = random.choice(filenames)\n","image = load_img(\"../input/train/train/\"+sample)\n","plt.imshow(image)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"b244e6b7715a04fc6df92dd6dfa3d35c473ca600"},"source":["# Model Oluşturma\n","\n","Incetipon'un Kerastaki versiyonunu (InceptionV3) import ediyoruz, epochs = 5 ayarlıyoruz, 512 gizli katman ekliyoruz ve son olarak da fazladan bir sigmoid \"relu\" aktivasyonlu bir katman ekliyoruz. "]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"8c9f833c1441b657c779844912d0b8028218d454","trusted":true},"outputs":[],"source":["from keras.models import Sequential\n","from keras import layers\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n","from keras import applications\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras.applications import InceptionV3\n","from keras.models import Model\n","\n","image_size = 224\n","input_shape = (image_size, image_size, 3)\n","\n","epochs = 5\n","batch_size = 16\n","\n","pre_trained_model = InceptionV3(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n","    \n","for layer in pre_trained_model.layers[:15]:\n","    layer.trainable = False\n","\n","for layer in pre_trained_model.layers[15:]:\n","    layer.trainable = True\n","    \n","last_layer = pre_trained_model.get_layer('block5_pool')\n","last_output = last_layer.output\n","    \n","# Flatten the output layer to 1 dimension\n","x = GlobalMaxPooling2D()(last_output)\n","# 512 gizli birimli katman ekleme\n","x = Dense(512, activation='relu')(x)\n","# Dropout oranımız: 0.5\n","x = Dropout(0.5)(x)\n","# Sınıflandırma için sigmoid katman ekleme\n","x = layers.Dense(1, activation='sigmoid')(x)\n","\n","model = Model(pre_trained_model.input, x)\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n","              metrics=['accuracy'])\n","\n","model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"a29ebfd697dd7183a1a1345ea41ec138874340b7"},"source":["# Test ve Train Veri Kümelerini Hazırlama\n","\n","Burada % 10 validasyon, % 10 test, % 80 train yapacağımız için validasyona %10 (0.1) verdik."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4eeb7af8dcf02c4ef5ca744c8305c51a2f5cedef","trusted":true},"outputs":[],"source":["train_df, validate_df = train_test_split(df, test_size=0.1)\n","train_df = train_df.reset_index()\n","validate_df = validate_df.reset_index()\n","\n","total_train = train_df.shape[0]\n","total_validate = validate_df.shape[0]"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"ff760be9104f7d9492467b8d9d3405011aa77d11"},"source":["# Training Oluşturucu\n","\n","Resim verilerini train etmek adına oluşturduk ve bunu tensorflowun \"flow_from_dataframe\" metoduyla train oluşturucu olarak kullanmak istediğimiz formata dönüştürdük."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4d1c7818703a8a4bac5c036fdea45972aa9e5e9e","trusted":true},"outputs":[],"source":["train_datagen = ImageDataGenerator(\n","    rotation_range=15,\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    width_shift_range=0.1,\n","    height_shift_range=0.1\n",")\n","\n","train_generator = train_datagen.flow_from_dataframe(\n","    train_df, \n","    \"../input/train/train/\", \n","    x_col='filename',\n","    y_col='category',\n","    class_mode='binary',\n","    target_size=(image_size, image_size),\n","    batch_size=batch_size\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"859c7b2857939c19fd2e3bb32839c9f7deb5aa3f"},"source":["# Validasyon Oluşturucu\n","\n","Yukarıdaki işlemin aynısını validasyon için yapıyoruz fakat buradaki datagen değişkenimizin parametrelerini yukarıdaki gibi sınırlandırmamıza gerek yok çünkü validasyon sadece %10'luk bir dilimi kapsadığından performans kaybı göz ardı edilebilir, yani parametre sınırlandırmamıza gerek yoktur."]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"7925e16bcacc89f4484fb6fe47e54d6420af732e","trusted":true},"outputs":[],"source":["validation_datagen = ImageDataGenerator(rescale=1./255)\n","validation_generator = validation_datagen.flow_from_dataframe(\n","    validate_df, \n","    \"../input/train/train/\", \n","    x_col='filename',\n","    y_col='category',\n","    class_mode='binary',\n","    target_size=(image_size, image_size),\n","    batch_size=batch_size\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"6e17fc1f002fedd60febb78fee5e81770640b909"},"source":["# Oluşturulan örnek resimleri görme"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"23d923dba747f8b47dc75569244cecc6f70df321","trusted":true},"outputs":[],"source":["example_df = train_df.sample(n=1).reset_index(drop=True)\n","example_generator = train_datagen.flow_from_dataframe(\n","    example_df, \n","    \"../input/train/train/\", \n","    x_col='filename',\n","    y_col='category',\n","    class_mode='binary'\n",")\n","plt.figure(figsize=(12, 12))\n","for i in range(0, 9):\n","    plt.subplot(3, 3, i+1)\n","    for X_batch, Y_batch in example_generator:\n","        image = X_batch[0]\n","        plt.imshow(image)\n","        break\n","plt.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"5cd8df64e794ed17de326b613a9819e7da977a0e"},"source":["# Modeli Fit etme (Uyarlama)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"0836a4cc8aa0abf603e0f96573c0c4ff383ad56b","trusted":true},"outputs":[],"source":["# fine-tune işlemleri\n","history = model.fit_generator(\n","    train_generator,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=total_validate//batch_size,\n","    steps_per_epoch=total_train//batch_size)"]},{"cell_type":"markdown","metadata":{"_uuid":"a624dbb9f5195e47f79c8f2a73d63d337b3cffa2"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e196e7807ffd55aa404481acdf2fc96e01c238aa","trusted":true},"outputs":[],"source":["loss, accuracy = model.evaluate_generator(validation_generator, total_validate//batch_size, workers=12)\n","print(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"37e05b06e4131600f27d663f2098a2310750f13c","trusted":true},"outputs":[],"source":["def plot_model_history(model_history, acc='acc', val_acc='val_acc'):\n","    fig, axs = plt.subplots(1,2,figsize=(15,5))\n","    axs[0].plot(range(1,len(model_history.history[acc])+1),model_history.history[acc])\n","    axs[0].plot(range(1,len(model_history.history[val_acc])+1),model_history.history[val_acc])\n","    axs[0].set_title('Model Accuracy')\n","    axs[0].set_ylabel('Accuracy')\n","    axs[0].set_xlabel('Epoch')\n","    axs[0].set_xticks(np.arange(1,len(model_history.history[acc])+1),len(model_history.history[acc])/10)\n","    axs[0].legend(['train', 'val'], loc='best')\n","    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n","    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n","    axs[1].set_title('Model Loss')\n","    axs[1].set_ylabel('Loss')\n","    axs[1].set_xlabel('Epoch')\n","    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n","    axs[1].legend(['train', 'val'], loc='best')\n","    plt.show()\n","    \n","plot_model_history(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"800b2cbabf53dd1725edfa1d82bcf31f05217222","trusted":true},"outputs":[],"source":["Y_val = validate_df['category']\n","y_pred =  model.predict_generator(validation_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"834bd766b3fa473bf85328d10625a38adbfb5cd9","trusted":true},"outputs":[],"source":["threshold = 0.5\n","y_final = np.where(y_pred > threshold, 1,0)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"7c427f212c00d161924fa5747c8dc23b19e9787a","trusted":true},"outputs":[],"source":["y_final.size"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"875a42b6dee96997a8cbc4f4d7839aabd047cae0","trusted":true},"outputs":[],"source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","# Validasyon kümesinden tahmin yap\n","\n","# confusion matrix hesabı\n","confusion_mtx = confusion_matrix(Y_val, y_final) \n","# confusion matrix görselleştirme\n","f,ax = plt.subplots(figsize=(8, 8))\n","sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"20e4ce1c5271a7f36364a69972ba3c3f1219ee6a","trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","# Sınıflandırma raporu oluştur\n","report = classification_report(Y_val, y_final, target_names=['0','1'])\n","\n","print(report)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"764dc66e4b2bc558f3a0f90b80bb802f5b3d45a8"},"source":["# Test Verisini Hazırlama"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c35e70d3e1e4834dbbf840fa0ea08c049bfcd915","trusted":true},"outputs":[],"source":["test_filenames = os.listdir(\"../input/test1/test1\")\n","test_df = pd.DataFrame({\n","    'filename': test_filenames\n","})\n","nb_samples = test_df.shape[0]"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"291bc3996dce8d05e174b27d64f03996d3e8038e"},"source":["# Test oluşturucu işlemleri"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"52249ec1c35fb1be3adef386be245de3794e55aa","trusted":true},"outputs":[],"source":["test_gen = ImageDataGenerator(rescale=1./255)\n","test_generator = test_gen.flow_from_dataframe(\n","    test_df, \n","    \"../input/test1/test1/\", \n","    x_col='filename',\n","    y_col=None,\n","    class_mode=None,\n","    batch_size=batch_size,\n","    target_size=(image_size, image_size),\n","    shuffle=False\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"2fa580afca2931ec5ce374e732d8c1789d03f2ed"},"source":["# Tahmin"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"4782eb23fa7d003f0e2415d995894017edb2d896","trusted":true},"outputs":[],"source":["predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n","threshold = 0.5\n","test_df['category'] = np.where(predict > threshold, 1,0)"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"ce72a83f80d6e012b12b82c8ee3365d671a3b307"},"source":["# Tahmin edilmiş sonucu görelim"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"98b41dc83075e6297137fb45bf703c313dd4ae28","trusted":true},"outputs":[],"source":["sample_test = test_df.sample(n=9).reset_index()\n","sample_test.head()\n","plt.figure(figsize=(12, 12))\n","for index, row in sample_test.iterrows():\n","    filename = row['filename']\n","    category = row['category']\n","    img = load_img(\"../input/test1/test1/\"+filename, target_size=(256, 256))\n","    plt.subplot(3, 3, index+1)\n","    plt.imshow(img)\n","    plt.xlabel(filename + '(' + \"{}\".format(category) + ')')\n","plt.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"_uuid":"d1ca25943e73aa20a37f9fb8670ee430caeaaf1f"},"source":["# Sonuç\n","\n","Sonuç olarak 1 saat 23 dakikada model Google Colab üzerinde train edilmiş ve %87 accuracy değerine ulaşılmıştır.\n","\n","<font color=yellow>100/100 [==============================] - ETA: 0s - loss: nan - accuracy: 0.8732  WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy</font>"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"cce9f3e2ffff0693d79d84590ed71fbbca7c3c7c","trusted":true},"outputs":[],"source":["submission_df = test_df.copy()\n","submission_df['id'] = submission_df['filename'].str.split('.').str[0]\n","submission_df['label'] = submission_df['category']\n","submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n","submission_df.to_csv('submission_13010030.csv', index=False)\n","\n","plt.figure(figsize=(10,5))\n","sns.countplot(submission_df['label'])\n","plt.title(\"(Test data)\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# SHAP ile açıklama\n","\n","SHAP'ın PermutationExplainer metoduyla resimleri sınıflandırmadaki hataları görselleştirme işlemleri yapılmıştır."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["masker = shap.maskers.Image(\"blur(28,28)\", X_train[0].shape)\n","\n","explainer = shap.PermutationExplainer(model, masker, output_names=class_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y_preds = model.predict(X_test[:4])\n","\n","Y_preds = Y_preds.argsort()[:, ::-1]\n","Y_labels = [[class_labels[val] for val in row] for row in Y_preds]\n","Y_labels=np.array(Y_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["shap.image_plot(shap_values, labels=Y_labels)\n","shap.image_plot(shap_values[:,:,:,:,:5], labels=Y_labels[:,:5])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# LIME ile Açıklama\n","\n","Aşağıda Colab'ın CUDA özelliğinden faydalanarak LIME ile labelleri (etiketleri) açıklama işlemleri yapılmıştır."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def batch_predict(images):\n","    device = \"cuda\"\n","    model.eval()\n","    model.to(device)\n","    batch = torch.stack([transform(img.to_pil()) for img in images])\n","    batch = batch.to(device)\n","    logits = model(batch)\n","    probs = torch.nn.functional.softmax(logits, dim=1)\n","    return probs.detach().cpu().numpy()\n","\n","explainer = LimeImage(predict_function=batch_predict)\n","explanations = explainer.explain(img, hide_color=0, num_samples=1000)\n","explanations.ipython_plot(index=0, class_names=idx2label)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"}}},"nbformat":4,"nbformat_minor":4}
